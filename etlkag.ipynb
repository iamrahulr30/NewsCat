{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# News Article Classification","metadata":{}},{"cell_type":"code","source":"!pip install feedparser \n!pip install newspaper3k","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport feedparser as fp\nfrom  newspaper import Article\nfrom datetime import datetime\nimport requests\nfrom bs4 import BeautifulSoup\nimport numpy as np\nimport time\nimport pytz\nimport random","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sources = {'terrorism': ['https://www.state.gov/rss-feed/counterterrorism/feed/',\n                          'https://globalnews.ca/tag/terrorism/feed/',\n                          'https://www.9news.com.au/terrorism/rss'],\n           \n 'political': ['https://globalnews.ca/politics/feed/',\n              'https://www.aljazeera.com/xml/rss/all.xml',\n              'https://globalnews.ca/politics/feed/'],\n           \n 'protest': ['https://www.theguardian.com/world/protest/rss',\n              'https://globalnews.ca/tag/protest/feed/'],\n           \n 'natural_disaster': ['https://www.theguardian.com/world/natural--disasters/rss',\n                      'https://globalnews.ca/tag/natural-disasters/feed/'],\n           \n 'positive': ['https://www.positive.news/feed/',\n              'https://www.goodnewsnetwork.org/feed/'],\n           \n 'others': ['https://www.theguardian.com/science/rss',\n              'https://globalnews.ca/science/feed/',\n              'https://www.sciencenews.org/feed']}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_content(url):\n    content = Article(url)\n    content.download()\n    content.parse()\n    return content.text.replace(\"\\n\" , \" \").lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_content(\"https://globalnews.ca/news/10219172/rcmp-quebec-restauarant-stabbing-terrorism/\")[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fetch_data(sources):\n    main_ = { \"title\" : [] , \"content\" : [] , \"label\" : [] }\n    for class_ , li in sources.items():\n        for i in li :\n            source_ = fp.parse(i)\n            if source_.bozo == False :\n                print(len(source_.entries))\n                for data in source_.entries : \n                    main_[\"title\"].append(data.title.lower())\n                    content = get_content(data.link)\n                    if content == '':\n                        print(i.link)\n                        content = data.summary_detial.value\n                    main_[\"content\"].append(content)\n                    main_[\"label\"].append(class_)\n            elif source_.bozo == True :\n                print(i)\n\n    return main_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = fetch_data(sources)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data[\"title\"]), len(data[\"content\"]), len(data[\"label\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"value_counts = df.label.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\n\nfig = px.bar(x=value_counts.index, y=value_counts.values, labels={'x':'Category', 'y':'Count'})\nfig.update_layout(title='Value Counts of Categories',\n                  xaxis_title='Category',\n                  yaxis_title='Count')\n\n# Show the plot\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nfrom nltk.stem.snowball import PorterStemmer , SnowballStemmer\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\n\nstop_words_set = set(STOP_WORDS)\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\nstemmer_ = SnowballStemmer(\"english\")\n\ndef remove_stopwords(text):\n    content = []\n    for word in text.lower().split():\n        if word not in stop_words_set :\n            content.append(word)\n            \n    return \" \".join(content)\n\n\ndef stemmer(text):\n    doc = nlp(text)\n    stemmed_content = [stemmer_.stem(token.lemma_) for token in doc]\n    return \" \".join(stemmed_content)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nimport string\ndef word_counts(word_list) :\n    word_count = Counter()\n    for i in word_list:\n        word_count.update([j for j in i.split()])\n        \n    return word_count\n\ndef remove_puncs(text):\n    translator = str.maketrans('', '', string.punctuation)\n    return text.translate(translator)\n    \n    return text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"soup\"] = df[\"title\"] + \" \" + df[\"content\"].replace('continue reading' , \" \")\ndf[\"soup\"] = df[\"soup\"].apply(remove_stopwords)\ndf[\"soup\"]  = df[\"soup\"].apply(stemmer)\ndf[\"soup\"]  = df[\"soup\"].apply(remove_puncs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_counts(df[\"soup\"].to_list()).most_common()[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = list(sources.keys())\nfor i in sources :\n    temp = df.query(f\" label == '{i}'\")\n    print(word_counts(temp[\"soup\"].to_list()).most_common()[:6] , i)\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab = word_counts(df[\"soup\"])\nlen(vocab)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_len = len(vocab)\nvocab_len","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(df.soup.to_list())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tokenizer.index_word)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_ = sorted([len(i.split()) for i in df.soup.to_list()] , reverse = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_ = np.array(len_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Counter(len_).most_common()[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_text(texts) : \n    sequences = tokenizer.texts_to_sequences(texts)\n    padded_sequences = pad_sequences(sequences, maxlen = 500 ,truncating='post', padding='post')\n    return padded_sequences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shuffled_df = df.sample(frac=1).reset_index(drop=True)\nshuffled_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequences = process_text(shuffled_df.soup.to_list())\nsequences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(sequences[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shuffled_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = np.array(shuffled_df.label.to_list()).reshape(-1 , 1)\nlabels[:3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder , OrdinalEncoder\n\none_hot = OneHotEncoder(sparse = False)\nlabels = one_hot.fit_transform(labels )\nlabels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_ = { i:o for i,o in  enumerate(list(one_hot.categories_[0]))}\ndict_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_temp, y_train, y_temp = train_test_split(sequences , labels, test_size=0.3, random_state=42)\nx_test, x_val, y_test, y_val = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ntest_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\nval_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"267/8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\ntrain_dataset = train_dataset.shuffle(buffer_size=10000).batch(batch_size)\ntest_dataset = test_dataset.shuffle(buffer_size=10000).batch(batch_size)\nval_dataset = val_dataset.shuffle(buffer_size=10000).batch(batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D , Dropout , GlobalMaxPooling1D , Input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = tf.test.gpu_device_name()\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device(device) :\n    model = Sequential([\n        Embedding(input_dim=vocab_len , output_dim = 64 ,   input_length=500),\n        GlobalMaxPooling1D(),\n        Dense(128, activation='relu'),\n        Dropout(0.5),  # Adjust dropout rate as needed\n        Dense(24, activation='relu'),\n        Dropout(0.5),  # Adjust dropout rate as needed\n        Dense(6, activation='softmax')  # Use 'softmax' for multi-class, 'sigmoid' for multi-label\n    ])\n    \n    \n    model.compile(loss='categorical_crossentropy', optimizer=Adam(0.01), metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler , ModelCheckpoint , ReduceLROnPlateau , TensorBoard\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', \n                                   patience=20, verbose=1, \n                                   mode='max', restore_best_weights=True)\n\nmodel_checkpoint = ModelCheckpoint(filepath='model_article.h5', \n                                       monitor='val_accuracy', verbose=1, \n                                   save_best_only=True, mode='max')\n    \nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,\n                              patience=2, min_lr=0.001)\n    \n\nlr_ind = []\ndef scheduler(epoch, lr):\n    if epoch < 30:\n        return lr\n    else:\n        lr_ind.append(lr * tf.math.exp(-0.2))\n        return lr * tf.math.exp(-0.2)\n    \nlr_schedule = LearningRateScheduler(scheduler)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device(device):\n    model.fit(\n        train_dataset ,\n        epochs=300 ,\n        callbacks=[\n            early_stopping #, model_checkpoint  , lr_schedule ,\n        ],\n    validation_data=val_dataset\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}